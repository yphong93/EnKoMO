#!/usr/bin/env python3
"""
NASA Bearing Dataset Preprocessing Script

NASA bearing datasetì˜ ê°œë³„ íŒŒì¼ë“¤ì„ í•˜ë‚˜ì˜ CSV íŒŒì¼ë¡œ í•©ì¹˜ëŠ” ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
ê° íŒŒì¼ì€ íƒ€ì„ìŠ¤íƒ¬í”„ í˜•íƒœì˜ ì´ë¦„ì„ ê°€ì§€ê³  ìˆìœ¼ë©°, 8ê°œ ì„¼ì„œ ì±„ë„ì˜ ì§„ë™ ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

Data format:
- ê° íŒŒì¼: 20,481 rows Ã— 8 columns (4 bearings Ã— 2 sensors each)
- Column names: Bearing1_X, Bearing1_Y, Bearing2_X, Bearing2_Y, Bearing3_X, Bearing3_Y, Bearing4_X, Bearing4_Y
- File naming: YYYY.MM.DD.HH.MM.SS
"""

import os
import csv
import math
from datetime import datetime
import re

def parse_filename_timestamp(filename):
    """íŒŒì¼ëª…ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ"""
    # íŒŒì¼ëª… í˜•íƒœ: 2003.10.22.12.06.24
    pattern = r'(\d{4})\.(\d{2})\.(\d{2})\.(\d{2})\.(\d{2})\.(\d{2})'
    match = re.match(pattern, filename)
    
    if match:
        year, month, day, hour, minute, second = map(int, match.groups())
        return datetime(year, month, day, hour, minute, second)
    else:
        return None

def load_single_file(filepath):
    """ë‹¨ì¼ ë°ì´í„° íŒŒì¼ ë¡œë“œ"""
    try:
        data = []
        with open(filepath, 'r') as f:
            for line in f:
                # íƒ­ìœ¼ë¡œ êµ¬ë¶„ëœ 8ê°œ ê°’ ì½ê¸°
                values = line.strip().split('\t')
                if len(values) == 8:
                    # floatìœ¼ë¡œ ë³€í™˜
                    row = [float(v) for v in values]
                    data.append(row)
        
        return data
    except Exception as e:
        print(f"Error loading {filepath}: {e}")
        return None

def calculate_mean(data):
    """í‰ê·  ê³„ì‚°"""
    return sum(data) / len(data)

def calculate_rms(data):
    """RMS (Root Mean Square) ê³„ì‚°"""
    return math.sqrt(sum(x * x for x in data) / len(data))

def calculate_std(data):
    """í‘œì¤€í¸ì°¨ ê³„ì‚°"""
    mean = calculate_mean(data)
    variance = sum((x - mean) ** 2 for x in data) / len(data)
    return math.sqrt(variance)

def calculate_max_abs(data):
    """ì ˆëŒ“ê°’ì˜ ìµœëŒ€ê°’ ê³„ì‚°"""
    return max(abs(x) for x in data)

def aggregate_data(data_files, method='rms'):
    """
    ê° íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ì§‘ê³„í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
    
    Args:
        data_files: (timestamp, filepath) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
        method: ì§‘ê³„ ë°©ë²• ('mean', 'rms', 'std', 'max')
    
    Returns:
        tuple: (aggregated_data, timestamps, column_names)
    """
    aggregated_data = []
    timestamps = []
    
    print(f"Processing {len(data_files)} files with {method} aggregation...")
    
    for i, (timestamp, filepath) in enumerate(data_files):
        if i % 50 == 0:
            print(f"Processing file {i+1}/{len(data_files)}: {os.path.basename(filepath)}")
        
        # íŒŒì¼ ë¡œë“œ
        file_data = load_single_file(filepath)
        if file_data is None:
            continue
        
        # ê° ì»¬ëŸ¼ë³„ë¡œ ì§‘ê³„ (8ê°œ ì»¬ëŸ¼)
        aggregated_row = []
        for col_idx in range(8):
            # í•´ë‹¹ ì»¬ëŸ¼ì˜ ëª¨ë“  ê°’ë“¤ ì¶”ì¶œ
            column_data = [row[col_idx] for row in file_data]
            
            # ì§‘ê³„ ë°©ë²•ì— ë”°ë¥¸ ì²˜ë¦¬
            if method == 'mean':
                value = calculate_mean(column_data)
            elif method == 'rms':
                value = calculate_rms(column_data)
            elif method == 'std':
                value = calculate_std(column_data)
            elif method == 'max':
                value = calculate_max_abs(column_data)
            else:
                raise ValueError(f"Unknown aggregation method: {method}")
            
            aggregated_row.append(value)
        
        aggregated_data.append(aggregated_row)
        timestamps.append(timestamp)
    
    # ì»¬ëŸ¼ëª… ìƒì„±
    columns = [
        'Bearing1_X', 'Bearing1_Y', 
        'Bearing2_X', 'Bearing2_Y',
        'Bearing3_X', 'Bearing3_Y', 
        'Bearing4_X', 'Bearing4_Y'
    ]
    
    return aggregated_data, timestamps, columns

def create_bearing_csv(input_dir, output_path, bearing_id=1, method='rms', max_files=None):
    """
    NASA bearing datasetì„ CSV íŒŒì¼ë¡œ ë³€í™˜
    
    Args:
        input_dir: ì…ë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ (ì˜ˆ: data/real_data/nasa_bearing/1st_test)
        output_path: ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (ì˜ˆ: data/real_data/bearing_1.csv)
        bearing_id: ë² ì–´ë§ ID (1, 2, 3, 4)
        method: ì§‘ê³„ ë°©ë²• ('mean', 'rms', 'std', 'max')
        max_files: ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ìˆ˜ (Noneì´ë©´ ëª¨ë“  íŒŒì¼)
    """
    
    if not os.path.exists(input_dir):
        raise ValueError(f"Input directory does not exist: {input_dir}")
    
    print(f"ğŸ” Scanning directory: {input_dir}")
    
    # ëª¨ë“  ë°ì´í„° íŒŒì¼ ì°¾ê¸°
    data_files = []
    for filename in os.listdir(input_dir):
        filepath = os.path.join(input_dir, filename)
        if os.path.isfile(filepath) and not filename.startswith('.'):
            timestamp = parse_filename_timestamp(filename)
            if timestamp is not None:
                data_files.append((timestamp, filepath))
    
    print(f"ğŸ“ Found {len(data_files)} data files")
    
    if len(data_files) == 0:
        raise ValueError("No valid data files found in the directory")
    
    # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
    data_files.sort(key=lambda x: x[0])
    
    # íŒŒì¼ ìˆ˜ ì œí•œ
    if max_files is not None:
        data_files = data_files[:max_files]
        print(f"ğŸ“Š Processing first {len(data_files)} files")
    
    print(f"â° Time range: {data_files[0][0]} to {data_files[-1][0]}")
    
    # ë°ì´í„° ì§‘ê³„
    aggregated_data, timestamps, columns = aggregate_data(data_files, method=method)
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    output_dir = os.path.dirname(output_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # CSV ì €ì¥
    print(f"ğŸ’¾ Saving to: {output_path}")
    print(f"ğŸ“Š Final dataset shape: ({len(aggregated_data)}, {len(columns)})")
    
    with open(output_path, 'w', newline='') as f:
        writer = csv.writer(f)
        
        # í—¤ë” ì“°ê¸°
        header = ['timestamp'] + columns
        writer.writerow(header)
        
        # ë°ì´í„° ì“°ê¸°
        for i, (timestamp, row) in enumerate(zip(timestamps, aggregated_data)):
            csv_row = [timestamp.strftime('%Y-%m-%d %H:%M:%S')] + list(row)
            writer.writerow(csv_row)
    
    print("âœ… Conversion completed successfully!")
    print(f"ğŸ“ˆ Dataset info:")
    print(f"   - Shape: ({len(aggregated_data)}, {len(columns)})")
    print(f"   - Columns: {columns}")
    print(f"   - Time span: {timestamps[0]} to {timestamps[-1]}")
    print(f"   - Data points: {len(timestamps)} time steps")
    
    # ê°„ë‹¨í•œ í†µê³„ ì¶œë ¥
    print("\nğŸ“Š Basic Statistics:")
    for i, col in enumerate(columns):
        values = [row[i] for row in aggregated_data]
        mean_val = calculate_mean(values)
        std_val = calculate_std(values)
        min_val = min(values)
        max_val = max(values)
        print(f"   {col}: mean={mean_val:.4f}, std={std_val:.4f}, min={min_val:.4f}, max={max_val:.4f}")
    
    return aggregated_data, timestamps

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ë³€í™˜ ì‹¤í–‰"""
    
    # ê¸°ë³¸ ì„¤ì •
    input_dir = "data/real_data/nasa_bearing/1st_test"
    output_dir = "data/real_data"
    
    print("ğŸ­ NASA Bearing Dataset Conversion Tool")
    print("=" * 50)
    
    # ê¸°ë³¸ bearing_1.csv íŒŒì¼ ìƒì„± (RMS ë°©ë²•)
    try:
        print(f"\nğŸ¯ Creating bearing_1.csv file (RMS method - best for vibration analysis)")
        
        data, timestamps = create_bearing_csv(
            input_dir=input_dir,
            output_path=f"{output_dir}/bearing_1.csv",
            bearing_id=1,
            method='rms',
            max_files=500  # ì²˜ìŒ 500ê°œ íŒŒì¼ ì²˜ë¦¬
        )
        
        print(f"ğŸ† bearing_1.csv created successfully!")
        print(f"ğŸ“„ File location: {output_dir}/bearing_1.csv")
        
        # ì¶”ê°€ë¡œ ë‹¤ë¥¸ ë°©ë²•ë“¤ë„ ìƒì„± (ì„ íƒì )
        print(f"\nğŸ”„ Creating additional datasets with different aggregation methods...")
        
        methods = ['mean', 'std', 'max']
        for method in methods:
            try:
                output_path = f"{output_dir}/bearing_1_{method}.csv"
                create_bearing_csv(
                    input_dir=input_dir,
                    output_path=output_path,
                    bearing_id=1,
                    method=method,
                    max_files=100  # ë” ì‘ì€ ìƒ˜í”Œë¡œ ë‹¤ë¥¸ ë°©ë²•ë“¤ í…ŒìŠ¤íŠ¸
                )
                print(f"âœ… {output_path} created")
            except Exception as e:
                print(f"âš ï¸  Warning: Could not create {method} dataset: {e}")
        
    except Exception as e:
        print(f"âŒ Error creating main dataset: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
